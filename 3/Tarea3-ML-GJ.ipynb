{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3 - Máquinas de Aprendizaje\n",
    "## Métodos No-Lineales\n",
    "### Integrantes: Gabriel Jara, Daniel San Martín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Small Circle inside Large Circle\n",
    "\n",
    "El objetivo de esta sección es experimentar con algunos modelos no-lineales sobre un problema de juguete\n",
    "generado para visualizar algoritmos de *clustering*. Se trata de un problema de clasificación a todas luces\n",
    "linealmente inseparable, en el sentido que, si denotamos por $\\textbf{x}\\in\\mathbb{R}^2$ un patrón de entrada y por $y\\in\\{0, 1\\}$ su correspondiente etiqueta, no existen $\\textbf{w}\\in\\mathbb{R}^2$ , $b\\in\\mathbb{R}$ tal que $y(\\textbf{w}^T\\textbf{x} + b) \\geq \\rho > 0$. El problema nos permite\n",
    "hacer un recorrido rápido por las grandes ideas en la búsqueda de la no-linealidad.\n",
    "\n",
    "<img src=\"img/1.png\">\n",
    "<center>Figura 1: Distribución deseada para la actividad 1. Los 2 colores representan 2 clases distintas.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Escriba una función que genere (aleatoriamente) n datos etiquetados de la forma $\\{(\\textbf{x}_1, y_1), ..., (\\textbf{x}_n, y_n)\\}$, $\\textbf{x}_i \\in \\mathbb{R}^2, ~ y_i \\in \\{0, 1\\}$, con una distribución de probabilidad que refleje la configuración linealmente inseparable que muestra la Fig. 1$^3$. Utilice esta función para crear $1000$ datos de entrenamiento y $1000$ datos de pruebas. Para medir la tendencia de los modelos a sobre-ajuste, agregue un $5\\%$ de ruido al dataset, generando $\\textbf{x}$’s cercanos a la frontera. Genere un gráfico que muestre datos de entrenamiento y pruebas, identificando cada clase con un color diferente (como lo muestra la Fig. 1).\n",
    "\n",
    "$^3$Puede generar datos aleatorios distribuidos de manera circular para luego etiquetar aquellos ubicados en el cı́rculo interior como $1$ y en el cı́rculo exterior $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def do_circles(n=2000,noisy_n=0.05):\n",
    "    generator = check_random_state(10)\n",
    "    linspace = np.linspace(0, 2 * np.pi, n // 2 + 1)[:-1]\n",
    "    outer_circ_x = np.cos(linspace)\n",
    "    outer_circ_y = np.sin(linspace)\n",
    "    inner_circ_x = outer_circ_x * .3\n",
    "    inner_circ_y = outer_circ_y * .3\n",
    "    X = np.vstack((np.append(outer_circ_x, inner_circ_x),\n",
    "    np.append(outer_circ_y, inner_circ_y))).T\n",
    "    y = np.hstack([np.zeros(n // 2, dtype=np.intp),\n",
    "    np.ones(n // 2, dtype=np.intp)])\n",
    "    X += generator.normal(scale=noisy_n, size=X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.5, random_state=42)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lo que sigue de la actividad utilice la siguiente función para graficar las fronteras de clasificación\n",
    "en base a la probabilidad que asigna cada algoritmo a la clase de un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_classifier(clf, X_train, Y_train, X_test, Y_test, model_type):\n",
    "    f, axis = plt.subplots(1, 1, sharex='col', sharey='row', figsize=(12, 8))\n",
    "    axis.scatter(X_train[:,0],X_train[:,1],s=30,c=Y_train,zorder=10,cmap='cool')\n",
    "    axis.scatter(X_test[:,0],X_test[:,1],s=20,c=Y_test,zorder=10,cmap='Greys')\n",
    "    XX, YY = np.mgrid[-2:2:200j, -2:2:200j]\n",
    "    if model_type == 'tree':\n",
    "        Z = clf.predict_proba(np.c_[XX.ravel(), YY.ravel()])[:,0]\n",
    "    elif model_type == 'ann':\n",
    "        Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "    else: raise ValueError('model type not supported')        \n",
    "    Z = Z.reshape(XX.shape)\n",
    "    Zplot = Z > 0.5\n",
    "    axis.pcolormesh(XX, YY, Zplot ,cmap='YlGn')\n",
    "    axis.contour(XX, YY, Z, alpha=1, colors=[\"k\", \"k\", \"k\"], linestyles=[\"--\", \"-\", \"--\"],\n",
    "    levels=[-2, 0, 2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Demuestre <u>experimentalmente</u> que una red neuronal artificial correspondiente a $1$ sola neurona (i.e. sin capas escondidas) no puede resolver satisfactoriamente el problema. Puede utilizar la función de activación y el método de entrenamiento que prefiera. Sea convincente: por ejemplo, intente modificar los parámetros de la máquina de aprendizaje, reportando métricas que permitan evaluar el desempeño\n",
    "del modelo en el problema con cada cambio efectuado. Adapte también la función ```plot_classifier``` para que represente gráficamente la solución encontrada por la red neuronal. Describa y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = do_circles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "n_h = 1\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(n_h, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, batch_size=100, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(hist.epoch, hist.history['loss']) \n",
    "plt.title(\"Training Loss vs epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_classifier(model, X_train, Y_train, X_test, Y_test, 'ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Testing Accuracy: \" + str(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Red neuronal de un único nodo no ha logrado generar una frontera que separe efectvamente ambas clases. Se observa que la función de pérdida, en este caso Entropia Cruzada Binaria, alcanza un mínimo de entrenamiento por sobre 0.56. La Exactitud (Accuracy) de clasificación sobre el set de testeo es de casi 0.7, o sea un 70% de las observaciones logra ser bien clasificadas. \n",
    "\n",
    "Se repite el experimento utizando Mínimos Cuadrados como función de pérdida, para comprobar si mejora el anterior resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "n_h = 1\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(n_h, init='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='mean_squared_error', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, batch_size=100, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(hist.epoch, hist.history['loss']) \n",
    "plt.title(\"Training Loss vs epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_classifier(model, X_train, Y_train, X_test, Y_test, 'ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Testing Accuracy: \" + str(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mínimos Cuadrados no mejora significativamente el resultado anterior. La función de perdida disminuye su valor, pero no es comparable dado que es una métrica diferente. La efectividad del clasificador sobre el set de testeo es similar a la anterior. Se observa que el problema del clasificador no está en la función de pérdida, sino en su limitada arquitectura que sólo le permite trazar fronteras de clasificación lineales, siendo el problema no linealmente separable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Demuestre <u>experimentalmente</u> que una red neuronal artificial con $1$ capa escondida puede resolver satisfactoriamente el problema obtenido en (a). Puede utilizar la arquitectura y el método de entrenamiento que prefiera, pero en esta actividad puede optar tranquilamente por usar los hiper-parámetros que se entregan como referencia en el código de ejemplo. Cambie el número de neuronas $N_h$ en la red entre $2$ y $32$ en potencias de $2$, graficando el error de entrenamiento y pruebas como función de $N_h$. Describa y explique lo que observa. Utilice la función plot classifier, diseñada anteriormente, para construir gráficos de la solución en algunos casos representativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba en primer lugar aumentar el  número de nodos en la capa oculta de 1 a 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_h = 2\n",
    "model = Sequential()\n",
    "model.add(Dense(n_h, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, batch_size=100, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(hist.epoch, hist.history['loss']) \n",
    "plt.title(\"Training Loss vs epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_classifier(model, X_train, Y_train, X_test, Y_test, 'ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Testing Accuracy: \" + str(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia una mejora significativa respecto a la situación anterior, puesto que la efectividad del modelo se incrementa a sobre 0.85. La gráfica de la frontera de clasificación permite apreciar que al incorporar un nodo adicional la frontera puede representar una clasificación lineal en dos tramos, lo que explica la mejora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_h = 4\n",
    "model = Sequential()\n",
    "model.add(Dense(n_h, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, batch_size=100, verbose=0)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "test_acc = scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(hist.epoch, hist.history['loss']) \n",
    "plt.title(\"Training Loss vs epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_classifier(model, X_train, Y_train, X_test, Y_test, 'ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Testing Accuracy: \" + str(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se constata que con cuatro nodos en la capa oculta, la Red Neuronal logra efectivamente generar una frontera de clasificación que separa ambas clases. En consecuencia, la función de perdida logra decaer a cero, y la efectividad del predictor sobre la muestra de testeo llega a uno, denotando que todas las observaciones fueron bien clasificadas. \n",
    "\n",
    "Seguir aumentando los nodos en la capa oculta permitirá suavizar la frontera de clasificación, pero ya no podrá mejorar la clasificación, puesto que ya es 100% correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Demuestre <u>experimentalmente</u> que stump (árbol de clasificación de $1$ nivel) no puede resolver satisfactoriamente el problema anterior. Puede utilizar el criterio y la función de partición que prefiera. Sea\n",
    "convincente: por ejemplo, intente modificar los parámetros de la máquina, reportando métricas que permitan evaluar el desempeño del modelo en el problema con cada cambio efectuado. Adapte también la función ```plot_classifier``` para que represente gráficamente la solución encontrada por el árbol. Describa y explique lo que observa, reportando gráficos de la solución sólo para algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=1)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia que un árbol con sólo un nivel de profundidad no puede establecer una frontera de clasificación efectiva en este caso. El clasificador es incluso más limitado que la Red Neuronal con un nodo, al quedar limitado a trazados ortogonales a una de las dimensiones de las variables independientes. \n",
    "\n",
    "Se prueba a continuación cambiar el criterio de clasificación, originalmete coeficiente de Gino, para probar con entropía y confirmar si esto permite mejorar los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "\n",
    "clf=Tree(criterion='entropy', splitter='best', random_state=0, max_depth=1)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era predecible, el resultado no mejora con el cambio de criterio. Nuevamente, el problema está en la limitada arquitectura del modelo, que no permite resolver un problema no linealmente separable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Demuestre experimentalmente que un árbol de clasificación de múltiples niveles puede resolver satisfactoriamente el problema estudiado. Puede utilizar el criterio y la función de partición que prefiera, pero puede optar tranquilamente por usar los hiper-parámetros que se entregan como referencia en el código de ejemplo. Cambie el número de niveles admitidos en el árbol $N_t$ entre $2$ y $20$, graficando el error de entrenamiento y pruebas como función de $N_t$. Describa y explique lo que observa. Utilice la función ```plot_classifier```, diseñada anteriormente, para construir gráficos de la solución en algunos casos representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=2\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al configurar el árbol con dos niveles, inmediatamente se percibe una mejora significativa, gracias a que ahora puede establecer una fronteras de clasificación con dos secciones, las que tendrán que ser paralelos u ortogonales. En este caso se aprecia de a gráfica que resultaron paralelas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=3\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tercer nivel permitió que una nueva mejora, ahora la frontera tiene tres segmentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=4\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cuatro niveles se logra una fronetera de clasificación adecuada a la naturaleza del problema, alcanzando en este caso una efectividad en la clasificación del set de testeo de 0.994. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=5\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar un quinto nivel no mejoró la clasificación, puesto que si bien el árbol mejora algo en el set de entrenamiento, empeora su efectividad en el set de testeo, lo que evidencia sobreajuste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=6\n",
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De 5 niveles en adelante el árbol resultante ya no varía, puesto que los niveles adicionales no permiten mejorar la clasificación durante el entrenamiento. \n",
    "\n",
    "Se probará a continuación nuevamente el modelo de árbol con 4 niveles, pero esta vez con entropia como criterio de clasificación, para ver si se mejora los resultados anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_t=4\n",
    "clf=Tree(criterion='entropy', splitter='best', random_state=0, max_depth=n_t)\n",
    "clf.fit(X_train,Y_train)\n",
    "acc_test = clf.score(X_test,Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf,X_train,Y_train,X_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el clasificador resultante con entropía fue levemente mejor que el obtenido con gini, de acuerdo a la precisión con que clasificó el set de testeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Como ya se demostró experimentalmente que este problema es linealmente inseperable, ahora se pide experimentar otra alternativa. Para ello deberá realizar una proyección de los datos a un nuevo espacio dimensional (manifold) en el cual se reconozcan sus patrones no lineales, para poder trabajarlos con fronteras lineales. Utilice la técnica de PCA con la ayuda de un Kernel Gaussiano ([2]) para extraer sus vectores con dimensión infinita de mayor varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "kpca = KernelPCA(n_components=2,kernel=\"rbf\", gamma=5)\n",
    "kpca = kpca.fit(X_train)\n",
    "Xkpca_train = kpca.transform(X_train)\n",
    "Xkpca_test = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Ajuste un algoritmo de aprendizaje con fronteras lineal para los datos proyectados en este nuevo espacio que captura sus componentes no lineales, muestre graficamente que el problema ahora puede ser resulto con estos métodos. Reporte métricas para evaluar el desempeño, comente y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf=Tree(criterion='gini', splitter='best', random_state=0, max_depth=1)\n",
    "clf.fit(Xkpca_train, Y_train)\n",
    "acc_test = clf.score(Xkpca_test, Y_test)\n",
    "print \"Test Accuracy = %f\"%acc_test\n",
    "print clf.tree_.max_depth\n",
    "plot_classifier(clf, Xkpca_train, Y_train, Xkpca_test,Y_test,'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizada la descomposición con PCA, el problema pasa a ser linealmente separable. Utilizando un árbol de decisión con un nivel de profundidad, se pudo sin problema generar un clasificador que presenta 100% de éxito en la clasificación sobre el set de testeo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bike Sharing: Predicción de Demanda Horaria\n",
    "\n",
    "En esta sección simularemos nuestra participación en el desafı́o Bike Sharing Demand de Kaggle [3]. El objetivo es predecir la demanda de bicicletas sobre la red Capital Bikeshare de la ciudad de Washington, D.C., en función de la hora del dı́a y otras variables descritas en la tabla 1. En principio, y como muestra la figura, la función es altamente no lineal y no determinista como función de la hora del dı́a. Su objetivo será entrenar un modelo para obtener un puntaje correspondiente al top-100 del \"leaderboard\" final, es decir superior o igual a $0.37748$. La función utilizada para evaluar este concurso Kaggle se proporciona en la siguiente ecuación:\n",
    "\n",
    "\\begin{equation}\n",
    "    E_{bikes}(\\textbf{y},\\hat{\\textbf{y}}) = \\frac1n \\sum_i (\\ln(y_i + 1) - \\ln(\\hat{y}_i + 1))^2,\n",
    "\\end{equation}\n",
    "\n",
    "donde $\\textbf{y},\\hat{\\textbf{y}} \\in \\mathbb{R}^n$ denotan los vectores de observaciones y predicciones respectivamente. Como el dataset de pruebas original no está disponible se fabricará uno, correspondiente al $20\\%$ de los datos de entrenamiento. Además, se pondrá a su disposición un subconjunto independiente de datos con propósitos de validación. Usted podrá descargar los archivos correspondientes al subconjunto de entrenamiento y pruebas a utilizar ejecutando los siguientes comandos:\n",
    "\n",
    "```wget http://octopus.inf.utfsm.cl/~ricky/bike_sharing_train.csv```\n",
    "\n",
    "```wget http://octopus.inf.utfsm.cl/~ricky/bike_sharing_val.csv```\n",
    "\n",
    "```wget http://octopus.inf.utfsm.cl/~ricky/bike_sharing_test.csv```\n",
    "\n",
    "<img src=\"img/2.png\">\n",
    "<center>Tabla 1: Atributos para el Problema 2 (*Bike Sharing*).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Cargue los datos de entrenamiento y pruebas como dataframes de *pandas*. Describa las variables invo-\n",
    "lucradas en el problema, explorando el tipo de datos de que se trata, el número de valores distintos y, si\n",
    "corresponde, un gráfico (e.g. un histograma) que resuma su comportamiento. Su primera operación de\n",
    "pre-procesamiento de datos será obtener la hora del dı́a desde el campo fecha (que en este momento es\n",
    "de tipo string), creando una nueva columna denominada *hour* y de tipo *int*. Para hacer esta operación\n",
    "se concatenarán los dataframes de entrenamiento y pruebas y luego se volverán a separar manteniendo\n",
    "la separación original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dftrain = pd.read_csv('data/bike_sharing_train.csv')\n",
    "dfval = pd.read_csv('data/bike_sharing_val.csv')\n",
    "dftest = pd.read_csv('data/bike_sharing_test.csv')\n",
    "ntrain = len(dftrain)\n",
    "nval = len(dftrain) + len(dfval)\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['hour'] = pd.to_numeric(df['hour'])\n",
    "\n",
    "print '\\nSummary - dataframe completo:\\n'\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Entrene un árbol de regresión para resolver el problema usando parámetros por defecto. Con este\n",
    "fin, construya una matriz $\\textbf{X}_{train}$ de forma $n_{train} \\times d_1$ que contenga los datos de entrenamiento en sus filas, seleccionando las columnas que desee/pueda utilizar para el entrenamiento. Implemente además, la función de evaluación que hemos definido anteriormente para este problema. Evalúe el árbol de regresión ajustado a los datos de entrenamiento sobre el conjunto de entrenamiento y pruebas. Construya un gráfico que compare las predicciones con los valores reales. En este punto usted debiese tener un modelo con puntaje del orden de $0.59$, lo que lo dejará más o menos en la posición $2140$ de la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def eval_bikemodel(y_predict,y_true):\n",
    "    diff = np.log(y_predict+1.0) - np.log(y_true+1.0)\n",
    "    return np.sqrt(np.sum(np.square(diff))/len(y_predict))\n",
    "\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour']]\n",
    "Ydf=df.ix[:,'count']\n",
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n",
    "\n",
    "model = Tree(random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "score_test = model.score(X_test,Y_test)\n",
    "print \"SCORE TEST=%f\"%score_test\n",
    "\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "Y_pred_test = model.predict(X_test)\n",
    "kagg_train = eval_bikemodel(Y_pred_train,Y_train)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "kagg_test = eval_bikemodel(Y_pred_test,Y_test)\n",
    "print \"KAGG EVAL TRAIN =%f\"%kagg_train\n",
    "print \"KAGG EVAL VALIDATION =%f\"%kagg_val\n",
    "print \"KAGG EVAL TEST =%f\"%kagg_test\n",
    "print \"Max Depth: \"+ str(model.tree_.max_depth)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Y_test,Y_pred_test,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Mejore el árbol de regresión definido en el punto anterior haciendo modificaciones a los hiper-parámetros del modelo. Por ejemplo, como estos modelos tienden a sobre-ajustar, podrı́a intentar limitar la profundidad del árbol (¿Por qué esto debiese ayudar?). Naturalmente, está absolutamente prohibido tomar este tipo de decisiones en función del resultado de pruebas. Debe realizar estas elecciones evaluando sobre el conjunto de validación. Si no desea utilizarlo, y prefiere implementar validación cruzada\n",
    "u otra técnica automática, tiene la ventaja de poder usar el conjunto de validación como parte del\n",
    "entrenamiento. Con estas modificaciones debiese poder mejorar su ranking en unas $300$ posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_depth = 0\n",
    "kagg_validated = 1\n",
    "\n",
    "for d in range(1,29):\n",
    "    model = Tree(random_state=0, max_depth=d)\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "    print \"Max Depth: \"+ str(model.tree_.max_depth)\n",
    "    print ''\n",
    "    if kagg_val < kagg_validated:\n",
    "        best_depth = d\n",
    "        kagg_validated = kagg_val\n",
    "print ''\n",
    "print 'BEST TREE MODEL:'\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_validated\n",
    "print \"Max Depth: \"+ str(best_depth)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Mejore el árbol de regresión definido en el punto anterior haciendo modificaciones sobre la representa-\n",
    "ción utilizada para aprender desde los datos. Por ejemplo, los histogramas que construyó en el punto\n",
    "(a) ası́ como la forma especial de la función de evaluación, sugieren una cierta transformación de la\n",
    "variable respuesta. Podrı́a intentar también normalizando los datos o normalizando la respuesta. Otra\n",
    "opción es intentar rescatar algo más acerca de la fecha (anteriormente sólo se extrajo la hora), como por\n",
    "ejemplo el año o el dı́a de la semana (’lunes’,’martes’, etc) que corresponde. Sea creativo, este paso le\n",
    "debiese reportar un salto de calidad muy significativo. Una observación importante es que si hace una\n",
    "transformación a la variable respuesta (por ejemplo raı́z cuadrada), debe invertir esta transformación\n",
    "antes de evaluar el desempeño con eval bikemodel (por ejemplo, elevar al cuadrado si tomó raı́z cua-\n",
    "drada). Con modificaciones de este tipo, podrı́a mejorar su ranking en unas $1000$ posiciones, entrando\n",
    "ya al top-$1000$ con un score del orden de $0.45$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek#0:lunes,6:domingo\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "df['year'] = pd.to_numeric(df['year'])\n",
    "\n",
    "Xdf = df.ix[:,['season','holiday','workingday','weather','temp','atemp','humidity','windspeed','hour','cday', 'year']]\n",
    "\n",
    "print '\\nSummary - dataframe completo:\\n'\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_depth = 0\n",
    "kagg_validated = 1\n",
    "\n",
    "for d in range(1,29):\n",
    "    model = Tree(random_state=0, max_depth=d)\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred_val = model.predict(X_val)\n",
    "    kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "    print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "    print \"Max Depth: \"+ str(model.tree_.max_depth)\n",
    "    print ''\n",
    "    if kagg_val < kagg_validated:\n",
    "        best_depth = d\n",
    "        kagg_validated = kagg_val\n",
    "print ''\n",
    "print 'BEST TREE MODEL:'\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_validated\n",
    "print \"Max Depth: \"+ str(best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_x = StandardScaler().fit(X_train)\n",
    "X_train_sc = scaler_x.transform(X_train)\n",
    "\n",
    "model = Tree(random_state=0, max_depth=11)\n",
    "model.fit(X_train_sc,Y_train)\n",
    "Y_pred_val = model.predict(scaler_x.transform(X_val))\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"Max Depth: \"+ str(model.tree_.max_depth)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ln = np.log(X_train+1)**2\n",
    "X_val_ln = np.log(X_val+1)**2\n",
    "\n",
    "model = Tree(random_state=0, max_depth=11)\n",
    "model.fit(X_train_ln,Y_train)\n",
    "Y_pred_val = model.predict(X_val_ln)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print \"Max Depth: \"+ str(model.tree_.max_depth)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Entrene una SVM no lineal para resolver el problema midiendo el efecto de las distintas representaciones\n",
    "que haya descubierto hasta este punto. Un detalle importante es que antes de entrenar la SVM serı́a\n",
    "aconsejable hacer dos tipos de pre-procesamiento adicional de los datos: (i) codificar las variables\n",
    "categóricas en un modo apropiado - por ejemplo como vector binario con un 1 en la posición del\n",
    "valor adoptado-, (ii) escalar los atributos de modo que queden centrados y con rangos comparables.\n",
    "Usando parámetros por defecto para la SVM debiese obtener un score del orden de $0.344$, quedando\n",
    "definitivamente en el top-$10$ de la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary - Xdataframe dummies:\n",
      "\n",
      "            holiday    workingday         temp         atemp      humidity  \\\n",
      "count  10886.000000  10886.000000  10886.00000  10886.000000  10886.000000   \n",
      "mean       0.028569      0.680875     20.23086     23.655084     61.886460   \n",
      "std        0.166599      0.466159      7.79159      8.474601     19.245033   \n",
      "min        0.000000      0.000000      0.82000      0.760000      0.000000   \n",
      "25%        0.000000      0.000000     13.94000     16.665000     47.000000   \n",
      "50%        0.000000      1.000000     20.50000     24.240000     62.000000   \n",
      "75%        0.000000      1.000000     26.24000     31.060000     77.000000   \n",
      "max        1.000000      1.000000     41.00000     45.455000    100.000000   \n",
      "\n",
      "          windspeed      season_1      season_2      season_3      season_4  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      12.799395      0.246739      0.251056      0.251056      0.251148   \n",
      "std        8.164537      0.431133      0.433641      0.433641      0.433694   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        7.001500      0.000000      0.000000      0.000000      0.000000   \n",
      "50%       12.998000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       16.997900      0.000000      1.000000      1.000000      1.000000   \n",
      "max       56.996900      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "           ...            hour_23        cday_0        cday_1        cday_2  \\\n",
      "count      ...       10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean       ...           0.041889      0.142477      0.141374      0.142477   \n",
      "std        ...           0.200344      0.349554      0.348423      0.349554   \n",
      "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
      "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
      "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
      "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
      "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "             cday_3        cday_4        cday_5        cday_6     year_2011  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean       0.142660      0.140456      0.145508      0.145049      0.498071   \n",
      "std        0.349742      0.347475      0.352628      0.352166      0.500019   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "          year_2012  \n",
      "count  10886.000000  \n",
      "mean       0.501929  \n",
      "std        0.500019  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def eval_bikemodel(y_predict,y_true):\n",
    "    diff = np.log(y_predict+1.0) - np.log(y_true+1.0)\n",
    "    return np.sqrt(np.sum(np.square(diff))/len(y_predict))\n",
    "\n",
    "dftrain = pd.read_csv('data/bike_sharing_train.csv')\n",
    "dfval = pd.read_csv('data/bike_sharing_val.csv')\n",
    "dftest = pd.read_csv('data/bike_sharing_test.csv')\n",
    "ntrain = len(dftrain)\n",
    "nval = len(dftrain) + len(dfval)\n",
    "\n",
    "df = pd.concat([dftrain,dfval,dftest])\n",
    "df['hour'] = pd.to_datetime(df['datetime']).apply(lambda x: x.strftime('%H'))\n",
    "df['cday'] = pd.to_datetime(df['datetime']).dt.dayofweek\n",
    "df['hour'] = pd.to_numeric(df['hour'])\n",
    "df['cday'] = pd.to_numeric(df['cday'])\n",
    "df['year'] = pd.to_datetime(df['datetime']).dt.year\n",
    "df['year'] = pd.to_numeric(df['year'])\n",
    "Xdf=df.ix[:,['season','holiday','workingday','weather','temp','atemp',\n",
    "'humidity','windspeed','hour','cday', 'year']]\n",
    "\n",
    "Xdf = pd.get_dummies(Xdf,columns=['season', 'weather','hour','cday', 'year'])\n",
    "\n",
    "Ydf=df.ix[:,'count']\n",
    "\n",
    "print '\\nSummary - Xdataframe dummies:\\n'\n",
    "print Xdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xdf[0:ntrain].values\n",
    "X_val = Xdf[ntrain:nval].values\n",
    "X_test = Xdf[nval:].values\n",
    "Y_train = Ydf[0:ntrain].values\n",
    "Y_val = Ydf[ntrain:nval].values\n",
    "Y_test = Ydf[nval:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "X_train = scalerX.fit_transform(X_train)\n",
    "X_val = scalerX.fit_transform(X_val)\n",
    "X_test = scalerX.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL VAL =nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Mejore la SVM definida en el punto anterior haciendo modificaciones a los hiper-parámetros de la\n",
    "máquina ($C$, $\\epsilon$ o la misma función de kernel). Naturalmente, está absolutamente prohibido tomar este\n",
    "tipo de decisiones de diseño mirando el resultado de pruebas. Debe realizar estas elecciones evaluan-\n",
    "do sobre el conjunto de validación. Si no desea utilizarlo, y prefiere implementar validación cruzada\n",
    "u otra técnica automática, tiene la ventaja de poder usar el conjunto de validación como parte del\n",
    "entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGG EVAL VAL =nan\n"
     ]
    }
   ],
   "source": [
    "model = SVR(kernel='sigmoid', C=1,epsilon=0.01)\n",
    "\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred_val = model.predict(X_val)\n",
    "kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-05 epsilon = 1e-08\n",
      "KAGG EVAL VAL =1.450614\n",
      "\n",
      "C = 1e-05 epsilon = 1e-07\n",
      "KAGG EVAL VAL =1.450614\n",
      "\n",
      "C = 1e-05 epsilon = 1e-06\n",
      "KAGG EVAL VAL =1.450614\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ea96faeb0bb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepsilon_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mY_pred_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mkagg_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_bikemodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C_range = 10. ** np.arange(-5, 3)\n",
    "epsilon_range = 10. ** np.arange(-8, 1)\n",
    "\n",
    "best_C = \"none\"\n",
    "best_epsilon = \"none\"\n",
    "kagg_validated = 2\n",
    "\n",
    "for c in C_range:\n",
    "    for e in epsilon_range:\n",
    "        model = SVR(C=c,epsilon=e)\n",
    "        model.fit(X_train,Y_train)\n",
    "        Y_pred_val = model.predict(X_val)\n",
    "        kagg_val = eval_bikemodel(Y_pred_val,Y_val)\n",
    "        print \"C = \" +str(c)+ \" epsilon = \" + str(e)\n",
    "        print \"KAGG EVAL VAL =%f\"%kagg_val\n",
    "        print \"\"\n",
    "        if kagg_val < kagg_validated:\n",
    "            best_C = c\n",
    "            best_epsilon = e\n",
    "            kagg_validated = kagg_val\n",
    "\n",
    "print \"\"\n",
    "print \"Best C = \" +str(best_C)+ \" Best epsilon = \" + str(best_epsilon)\n",
    "print \"KAGG EVAL VAL =%f\"%kagg_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Evalúe el efecto de utilizar el dataset de validación para entrenamiento y seleccionar los parámetros estructurales del árbol de clasificación y la SVM usando validación cruzada. El código de ejemplo para esto ha sido proporcionado en las tareas $1$ y $2$, pero se adjunta de nuevo a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(Xm):\n",
    "        model = #define your model\n",
    "        model.fit(Xm[train], ym[train])\n",
    "        yhat_val = model.predict(Xm[val])\n",
    "    ytrue_val = ym[val]\n",
    "    score_fold = eval_bikemodel(yhat_val,ytrue_val)\n",
    "        mse_cv += score_fold\n",
    "mse_cv = mse_cv / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Evalúe el efecto de utilizar un ensamblado de $2$ máquinas de aprendizaje para predecir la demanda\n",
    "total de bicicletas. Un modelo se especializará en la predicción de la demanda de bicicletas de parte\n",
    "de usuarios registrados y otra en la predicción de la demanda de usuarios casuales. Hay razones claras\n",
    "para pensar que los patrones son distintos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ydf=df.ix[:,'count'] #demanda total\n",
    "Ydf=df.ix[:,'registered'] #demanda registrada\n",
    "Ydf=df.ix[:,'casual'] #demanda casual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Evalúe el efecto de utilizar un algoritmo genérico para ensamblar máquinas de aprendizaje para predecir\n",
    "la demanda total de bicicletas. Puede experimentar con una sola técnica (e.g. Random Forest), discuta\n",
    "la evolución a medida que aumenta el número de máquinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=10,max_depth=max_depth,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calidad de un Vino\n",
    "\n",
    "Dentro de las variedades del vino, existen distintas calidades de este, donde algunos gustan mas a algunas personas que otras, esto depende de la gran cantidad de quı́micos y procesos que se aplican a la producción de vino. Para el área de negocios el estimar cuál es la calidad del vino en base a la apreciación de la gente es una tarea bastante difı́cil.\n",
    "Para esta actividad se trabajará con dos datasets asociados a variantes tinto y blanco del vino Portugués \"Vinho Verde\" [4]. Debido a temas privados solo se cuenta atributos fisioquímicos asociados a un vino en particular, los cuales corresponden a $11$ atributos numéricos descritos en el siguiente link. Este problema puede ser abordado como clasificación de $11$ clases o de regresión, ya que el atributo a estimar, la calidad quality, es un valor entero entre $0$ y $10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Carge los dos dataset en un único dataframe de pandas, además de agregar una columna indicando si es vino tinto o blanco. Describa el dataset a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_red = pd.read_csv(\"data/winequality-red.csv\",sep=\";\")\n",
    "df_white = pd.read_csv(\"data/winequality-white.csv\",sep=\";\")\n",
    "df = pd.concat([df_red,df_white], axis=0)\n",
    "#genere atributo ’tipo’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Aborde este problema como si fuera de clasificación binaria para predecir si un vino es de calidad o no, es decir, utilice las distintas características fisioquı́micas presentes en los datos para estimar esta etiqueta. Para esto cree las matrices de entrenamiento y de pruebas, además de la etiqueta para ambos conjuntos, considerando como quality mayor a $5$ un vino de buena calidad. El conjunto de pruebas ($25 \\%$) será utilizado únicamente para verificar la calidad de los algoritmos a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['good_quality'] = [1 if q>5 else 0 for q in df.quality]\n",
    "#train and test split over df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Entrene un solo Árbol de Clasificación de múltiples niveles para resolver el problema. Puede variar los hiper-parámetros que prefiera, recuerde que las decisiones no pueden ser basadas mirando el conjunto de pruebas. Debido al desbalanceo que se produce en las dos clases mida la métrica *F1-score* [5] sobre el conjunto de entrenamiento y de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Entrene un ensamblador de árboles de múltiples niveles, mediante la técnica de *Random Forest*. Varı́e la cantidad de árboles de decisión utilizados en el ensamblado (```n_estimators```), realice un gráfico resumen del *F1-score* de entrenamiento y de pruebas en función de este hiper-parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=, max_depth=,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Entrene un ensamblador de árboles de múltiples niveles, mediante la técnica de *AdaBoost*. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (```n_estimators```), realice un gráfico resumen del *F1-score* de entrenamiento y de pruebas en función de este hiper-parámetro. Compare y analice con la técnica utilizada en d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(base_estimator=Tree(max_depth=), n_estimators=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Entrene alguna otra máquina de aprendizaje, elegida por usted, para resolver este problema. Elija los hiper-parámetros que estime convenientes intentando aumentar el *F1-score* obtenido por los algoritmos anteriores. Compare y analice estas $4$ maneras de resolver el problema definido en b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Defina un criterio para estimar la importancia de los distintos atributos en el ensamblado de *Random Forest*, implementelo sobre alguno de los ensambladores entrenados en d), haga un ranking de importancia de atributos ¿Es posible implementar este criterio sobre una técnica de *boost* como lo es *AdaBoost*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reconocimiento de Imágenes Sign Gestures\n",
    "\n",
    "MNIST es un dataset muy popular de dı́gitos escrito a mano que a servido para probar distintos algoritmos de Machine Learning relacionados con Computer Vision. Buscando nuevos desafı́os, investigadores generaron un dataset que podrı́a usarse eventualmente en aplicaciones reales, Sign Gestures, consta de imagenes del lenguaje de señas, estas tienen una resolución de $28\\times 28$ pixeles representados en una escala de grises $0-255$.\n",
    "La versión utilizada se atribuye a [8] y viene separada en $27455$ ejemplos de entrenamiento y $7172$ casos de pruebas. Las clases son mutualmente excluyentes y corresponden a las letras del alfabeto (ver imagen).\n",
    "\n",
    "<img src=\"img/3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Construya una función que cargue todos los datos de entrenamiento y pruebas del problema generando como salida: (i) dos matrices $X_{tr}$, $Y_{tr}$, correspondientes a las imágenes y etiquetas de entrenamiento, (ii) dos matrices $X_t$, $Y_t$, correspondientes a las imágenes y etiquetas de pruebas, y finalmente (iii) dos matrices $X_v$ , $Y_v$, correspondientes a imágenes y etiquetas que se usarán como conjunto de validación, es decir para tomar decisiones de diseño acerca del modelo. Este último conjunto debe ser extraı́do desde el conjunto de entrenamiento original y no debe superar las $7000$ imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_data():\n",
    "    train = pd.read_csv('data/sign_mnist_train.csv')\n",
    "    test = pd.read_csv('data/sign_mnist_test.csv')\n",
    "    y_tr = train['label']\n",
    "    x_tr = train.iloc[:,1:]\n",
    "    y_t = test['label']\n",
    "    x_t = test.iloc[:,1:]\n",
    "    #you need to add Xval: x_v,y_v\n",
    "    x_v = x_tr[:7000]\n",
    "    y_v = y_tr[:7000]\n",
    "    return(x_tr,x_v,x_t,y_tr,y_v,y_t)\n",
    "x_tr, x_v, x_t, y_tr, y_v , y_t= load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Construya una función que escale apropiadamente las imágenes antes de trabajar. Experimente sólo escalando los datos de acuerdo a la intensidad máxima de pixel (i.e., dividiendo por $255$) y luego centrando y escalándolos como en actividades anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Diseñe, entrene y evalúe una red neuronal para el problema partir de la representación original de las imágenes. Experimente con distintas arquitecturas, pre-procesamientos y métodos de entrenamiento, midiendo el error de clasificación sobre el conjunto de validación. En base a esta última medida de desempeño, decida qué modelo, de entre todos los evaluados, medirá finalmente en el conjunto de test. Reporte y discuta los resultados obtenidos. Se espera que logre obtener un error de pruebas menor o igual a $0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=x_tr.shape[1], init='uniform', activation='relu'))\n",
    "model.add(Dense(30, init='uniform', activation='relu'))\n",
    "model.add(Dense(25, init='uniform', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_tr.values, to_categorical(y_tr), nb_epoch=100, batch_size=128, verbose=1, validation_data=(x_v.values,to_categorical(y_v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Para la mejor red entrenada anteriormente construya la matriz de confusión de las distintas clases, para asi visualizar cuáles son las clases más difı́ciles de clasificar y con cuáles se confunden. Comente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Entrene una SVM no lineal sobre los pixeles con y sin pre-procesamiento. Puede utilizar el conjunto de validación para seleccionar hiper-parámetros, como el nivel de regularización aplicado y/o la función de kernel a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Entrene una árbol de clasificación sobre los pixeles con y sin pre-procesamiento. Puede utilizar el conjunto de validación para seleccionar hiper-parámetros, como la profundidad máxima del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "* [1] Keras: Deep Learning library for Theano and TensorFlow. https://keras.io/ \n",
    "* [2] Bernhard Schoelkopf, Alexander J. Smola, and Klaus-Robert Mueller. 1999. Kernel principal component analysis. In Advances in kernel methods, MIT Press, Cambridge, MA, USA 327-352.\n",
    "* [3] https://www.kaggle.com/c/bike-sharing-demand\n",
    "* [4] http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* [5] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1 score.html\n",
    "* [6] Dalal, N., Triggs, B. (2005, June). Histograms of oriented gradients for human detection. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05) (Vol. 1, pp. 886-893). IEEE.\n",
    "* [7] Forsyth, D. A., Ponce, J. (2002). Computer vision: a modern approach. Prentice Hall Professional Tech- nical Reference.\n",
    "* [8] https://www.kaggle.com/datamunge/sign-language-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
