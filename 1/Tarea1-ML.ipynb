{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tarea 1 - Máquinas de Aprendizaje\n",
    "\n",
    "### Integrantes: Gabriel Jara, Daniel San Martín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Regresión Lineal Ordinaria (LSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con un dataset conocido como *House Sales in King County*, USA, este se encuentra en Kaggle [1] y contiene los precios en el que se vendieron distintas casas en los Estados Unidos entre Mayo del 2014 y Mayo del 2015. Las casas tienen distintas caracterı́sticas que vienen descritas en el dataset, como la cantidad de habitaciones, cantidad de baños, número de pisos, ubicación geográfica, etc. La variable que nos interesará predecir a partir de los demás atributos será el precio de las casas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Construya un dataframe con los datos a analizar descargando los datos desde la URL adjunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/kc_house_data.csv\",sep = \",\",header = 0)\n",
    "df = df.drop(['id','date','zipcode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Describa brevemente el dataset utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 18 columns):\n",
      "price            21613 non-null float64\n",
      "bedrooms         21613 non-null int64\n",
      "bathrooms        21613 non-null float64\n",
      "sqft_living      21613 non-null int64\n",
      "sqft_lot         21613 non-null int64\n",
      "floors           21613 non-null float64\n",
      "waterfront       21613 non-null int64\n",
      "view             21613 non-null int64\n",
      "condition        21613 non-null int64\n",
      "grade            21613 non-null int64\n",
      "sqft_above       21613 non-null int64\n",
      "sqft_basement    21613 non-null int64\n",
      "yr_built         21613 non-null int64\n",
      "yr_renovated     21613 non-null int64\n",
      "lat              21613 non-null float64\n",
      "long             21613 non-null float64\n",
      "sqft_living15    21613 non-null int64\n",
      "sqft_lot15       21613 non-null int64\n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 3.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price      bedrooms     bathrooms   sqft_living      sqft_lot  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  2.161300e+04   \n",
       "mean   5.400881e+05      3.370842      2.114757   2079.899736  1.510697e+04   \n",
       "std    3.671272e+05      0.930062      0.770163    918.440897  4.142051e+04   \n",
       "min    7.500000e+04      0.000000      0.000000    290.000000  5.200000e+02   \n",
       "25%    3.219500e+05      3.000000      1.750000   1427.000000  5.040000e+03   \n",
       "50%    4.500000e+05      3.000000      2.250000   1910.000000  7.618000e+03   \n",
       "75%    6.450000e+05      4.000000      2.500000   2550.000000  1.068800e+04   \n",
       "max    7.700000e+06     33.000000      8.000000  13540.000000  1.651359e+06   \n",
       "\n",
       "             floors    waterfront          view     condition         grade  \\\n",
       "count  21613.000000  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean       1.494309      0.007542      0.234303      3.409430      7.656873   \n",
       "std        0.539989      0.086517      0.766318      0.650743      1.175459   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      3.000000      7.000000   \n",
       "50%        1.500000      0.000000      0.000000      3.000000      7.000000   \n",
       "75%        2.000000      0.000000      0.000000      4.000000      8.000000   \n",
       "max        3.500000      1.000000      4.000000      5.000000     13.000000   \n",
       "\n",
       "         sqft_above  sqft_basement      yr_built  yr_renovated           lat  \\\n",
       "count  21613.000000   21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean    1788.390691     291.509045   1971.005136     84.402258     47.560053   \n",
       "std      828.090978     442.575043     29.373411    401.679240      0.138564   \n",
       "min      290.000000       0.000000   1900.000000      0.000000     47.155900   \n",
       "25%     1190.000000       0.000000   1951.000000      0.000000     47.471000   \n",
       "50%     1560.000000       0.000000   1975.000000      0.000000     47.571800   \n",
       "75%     2210.000000     560.000000   1997.000000      0.000000     47.678000   \n",
       "max     9410.000000    4820.000000   2015.000000   2015.000000     47.777600   \n",
       "\n",
       "               long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000   21613.000000   21613.000000  \n",
       "mean    -122.213896    1986.552492   12768.455652  \n",
       "std        0.140828     685.391304   27304.179631  \n",
       "min     -122.519000     399.000000     651.000000  \n",
       "25%     -122.328000    1490.000000    5100.000000  \n",
       "50%     -122.230000    1840.000000    7620.000000  \n",
       "75%     -122.125000    2360.000000   10083.000000  \n",
       "max     -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Normalice los datos antes de trabajar. Explique la importancia/conveniencia de realizar esta operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df\n",
    "y = np.log(df['price'])\n",
    "mask = np.zeros(len(X))\n",
    "limit = int(len(X)*0.7)\n",
    "mask[:limit] = 1\n",
    "istrain = (mask== 1)\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "Xtrain = Xtrain.drop(['price'], axis=1)\n",
    "Xtest = Xtest.drop(['price'], axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled_train = pd.DataFrame(scaler.fit_transform(Xtrain), columns=Xtrain.columns)\n",
    "df_scaled_train.insert(df_scaled_train.shape[1], 'intercept', np.ones(df_scaled_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los datos en las columnas se encuentran en distintas escalas, al momento de aplicar los algoritmos de aprendizaje existirán columnas que ponderarán mucho más y otros muchos menos dada esta diferencia de magnitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Realice una regresión lineal de mı́nimos cuadrados básica. Explique la importancia/conveniencia del paso 4 y los argumentos que se deben entregar a la función que implementa la regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "# Regresion lineal\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(df_scaled_train, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *paso 4* se utiliza para agregar la columna de 1 a los datos $\\textbf{X}$ correspondiente a los $\\beta_0$ (intercepto) en la regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Construya una tabla con los pesos y Z-score correspondientes a cada predictor (variable). ¿Observa algún problema? Si es ası́, comente y proponga un metodo para eliminar dicho problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmaHat(X, y, yhat):\n",
    "    M, I = X.shape\n",
    "    return np.sqrt(1./(M - I - 1) * np.sum((y - yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Zscore(X, y, yhat, beta):\n",
    "    V = np.linalg.inv(np.dot(X.T, X))\n",
    "    v = np.diag(V)\n",
    "    sigh = sigmaHat(X, y, yhat)\n",
    "    z = beta/(sigh * np.sqrt(v))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = linreg.predict(df_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zs = Zscore(df_scaled_train, ytrain, yhat_val, linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>b10</th>\n",
       "      <th>b11</th>\n",
       "      <th>b12</th>\n",
       "      <th>b13</th>\n",
       "      <th>b14</th>\n",
       "      <th>b15</th>\n",
       "      <th>b16</th>\n",
       "      <th>b17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>-0.008086</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>5.693485e-02</td>\n",
       "      <td>0.022873</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.033366</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.046360</td>\n",
       "      <td>0.184577</td>\n",
       "      <td>4.593672e-02</td>\n",
       "      <td>3.226485e-02</td>\n",
       "      <td>-0.104759</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.187880</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>0.084412</td>\n",
       "      <td>-0.007149</td>\n",
       "      <td>13.033501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z-score</th>\n",
       "      <td>-3.034080</td>\n",
       "      <td>14.656026</td>\n",
       "      <td>7.530578e-07</td>\n",
       "      <td>7.597490</td>\n",
       "      <td>12.269887</td>\n",
       "      <td>14.785692</td>\n",
       "      <td>17.390702</td>\n",
       "      <td>20.536815</td>\n",
       "      <td>48.068186</td>\n",
       "      <td>6.824251e-07</td>\n",
       "      <td>8.586649e-07</td>\n",
       "      <td>-33.790551</td>\n",
       "      <td>6.889786</td>\n",
       "      <td>85.795087</td>\n",
       "      <td>-1.589882</td>\n",
       "      <td>23.568652</td>\n",
       "      <td>-2.346780</td>\n",
       "      <td>6307.518371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               b0         b1            b2        b3         b4         b5  \\\n",
       "coef    -0.008086   0.055111  5.693485e-02  0.022873   0.035505   0.033366   \n",
       "Z-score -3.034080  14.656026  7.530578e-07  7.597490  12.269887  14.785692   \n",
       "\n",
       "                b6         b7         b8            b9           b10  \\\n",
       "coef      0.042595   0.046360   0.184577  4.593672e-02  3.226485e-02   \n",
       "Z-score  17.390702  20.536815  48.068186  6.824251e-07  8.586649e-07   \n",
       "\n",
       "               b11       b12        b13       b14        b15       b16  \\\n",
       "coef     -0.104759  0.015266   0.187880 -0.004031   0.084412 -0.007149   \n",
       "Z-score -33.790551  6.889786  85.795087 -1.589882  23.568652 -2.346780   \n",
       "\n",
       "                 b17  \n",
       "coef       13.033501  \n",
       "Z-score  6307.518371  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['b' + str(i) for i in range(18)]\n",
    "df_sp = pd.DataFrame([linreg.coef_, zs], index=['coef', 'Z-score'], columns=cols)\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Estime el error de predicción del modelo usando validación cruzada con un número de \"folds\" igual a $K = 5$ y $K = 10$. Recuerde que para que la estimación sea razonable debe ajustar los pesos del modelo de nuevo, cada vez que trabaja sobre un determinado \"fold\". Mida el error real del modelo sobre el conjunto de pruebas, compare y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(scaler.transform(Xtest),columns=Xtest.columns)\n",
    "x_test.insert(x_test.shape[1], 'intercept', np.ones(x_test.shape[0]))\n",
    "\n",
    "yhat_test = linreg.predict(x_test)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE K=5: 0.064701633522\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "mse_cv = 0\n",
    "\n",
    "for train, val in kf.split(Xm):\n",
    "    cross_scaler = StandardScaler().fit(Xm[train])\n",
    "    df_cross_train = pd.DataFrame(cross_scaler.transform(Xm[train]),\n",
    "    columns=Xtrain.columns)\n",
    "    df_cross_train.insert(df_cross_train.shape[1], 'intercept',\n",
    "        np.ones(df_cross_train.shape[0]))\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(df_cross_train, ym[train])\n",
    "    df_cross_test = pd.DataFrame(cross_scaler.transform(Xm[val]),columns=Xtrain.columns)\n",
    "    df_cross_test.insert(df_cross_test.shape[1], 'intercept', np.ones(df_cross_test.shape[0]))\n",
    "    yhat_val = linreg.predict(df_cross_test)\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "\n",
    "mse_cv = mse_cv / 5\n",
    "print \"Training MSE K=5:\", mse_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE K=10: 0.0646829054256\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "mse_cv = 0\n",
    "\n",
    "for train, val in kf.split(Xm):\n",
    "    cross_scaler = StandardScaler().fit(Xm[train])\n",
    "    df_cross_train = pd.DataFrame(cross_scaler.transform(Xm[train]),\n",
    "    columns=Xtrain.columns)\n",
    "    df_cross_train.insert(df_cross_train.shape[1], 'intercept',\n",
    "        np.ones(df_cross_train.shape[0]))\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(df_cross_train, ym[train])\n",
    "    df_cross_test = pd.DataFrame(cross_scaler.transform(Xm[val]),columns=Xtrain.columns)\n",
    "    df_cross_test.insert(df_cross_test.shape[1], 'intercept', np.ones(df_cross_test.shape[0]))\n",
    "    yhat_val = linreg.predict(df_cross_test)\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "\n",
    "mse_cv = mse_cv / 10\n",
    "print \"MSE K=10:\", mse_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE:  0.0651691603876\n"
     ]
    }
   ],
   "source": [
    "yhat = linreg.predict(x_test)\n",
    "mse = np.mean(np.power(yhat - ytest, 2))\n",
    "print \"Testing MSE: \", mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) Mida los errores de predicción para cada dato de entrenamiento. Utilizando un \"quantile-quantile plot\" determine si es razonable la hipótesis de normalidad sobre los residuos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFq1OOE/0pWQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b60328990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab \n",
    "import scipy.stats as stats\n",
    "\n",
    "error = yhat - ytest\n",
    "stats.probplot(error, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Se generan dos muestreos de datos donde el valor de sus etiqueta siguen distribuciones distintas: Genere dos modelos, evalue y compare sus comportamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df.sample(3000)\n",
    "frames = []\n",
    "valor = np.log(df.price)\n",
    "\n",
    "for z in np.arange(int(np.min(valor)),int(np.max(valor))+1,0.5):\n",
    "    #frames.append(df[(np.log(df.price) >= z) & (np.log(df.price) < z+0.5)].head(500))\n",
    "    frames.append(df[(valor >= z) & (valor < z+0.5)].head(500))\n",
    "    \n",
    "df_B = pd.concat(frames).sample(3000)\n",
    "X_A = df_A.iloc[:,1:].values\n",
    "y_A = np.log(df_A.price)\n",
    "X_B = df_B.iloc[:,1:].values\n",
    "y_B = np.log(df_B.price)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain_A, Xval_A, ytrain_A, yval_A = train_test_split(X_A, y_A, test_size=0.3, random_state=42)\n",
    "Xtrain_B, Xval_B, ytrain_B, yval_B = train_test_split(X_B, y_B, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Xtrain_A = pd.DataFrame(Xtrain_A)\n",
    "Xval_A = pd.DataFrame(Xval_A)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled_train_A = pd.DataFrame(scaler.fit_transform(Xtrain_A), columns=Xtrain_A.columns)\n",
    "df_scaled_train_A.insert(df_scaled_train_A.shape[1], 'intercept', np.ones(df_scaled_train_A.shape[0]))\n",
    "\n",
    "df_scaled_test_A = pd.DataFrame(scaler.transform(Xval_A),columns=Xval_A.columns)\n",
    "df_scaled_test_A.insert(df_scaled_test_A.shape[1], 'intercept', np.ones(df_scaled_test_A.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE A: 0.0663436881053\n"
     ]
    }
   ],
   "source": [
    "linregA = lm.LinearRegression(fit_intercept = False)\n",
    "linregA.fit(df_scaled_train_A, ytrain_A)\n",
    "yhatA = linreg.predict(df_scaled_test_A)\n",
    "mseA = np.mean(np.power(yhatA - yval_A, 2))\n",
    "print \"MSE A:\", mseA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Xtrain_B = pd.DataFrame(Xtrain_B)\n",
    "Xval_B = pd.DataFrame(Xval_B)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled_train_B = pd.DataFrame(scaler.fit_transform(Xtrain_B), columns=Xtrain_B.columns)\n",
    "df_scaled_train_B.insert(df_scaled_train_B.shape[1], 'intercept', np.ones(df_scaled_train_B.shape[0]))\n",
    "\n",
    "df_scaled_test_B = pd.DataFrame(scaler.transform(Xval_B),columns=Xval_B.columns)\n",
    "df_scaled_test_B.insert(df_scaled_test_B.shape[1], 'intercept', np.ones(df_scaled_test_B.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE B: 0.208685055502\n"
     ]
    }
   ],
   "source": [
    "linregB = lm.LinearRegression(fit_intercept = False)\n",
    "linregB.fit(df_scaled_train_B, ytrain_B)\n",
    "yhatB = linreg.predict(df_scaled_test_B)\n",
    "mseB = np.mean(np.power(yhatB - yval_B, 2))\n",
    "print \"MSE B:\", mseB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Selección de Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el dataframe de la actividad anterior,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Construya una función que implemente Forward Step-wise Selection (FSS). Es decir, partiendo con un modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo. Ordene el eje $x$ de menor a mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected = lat-long ...\n",
      "totalvars=2, mse = 0.257649\n",
      "selected = sqft_living ...\n",
      "totalvars=3, mse = 0.131349\n",
      "selected = sqft_living15 ...\n",
      "totalvars=4, mse = 0.106339\n",
      "selected = grade ...\n",
      "totalvars=5, mse = 0.093274\n",
      "selected = yr_built ...\n",
      "totalvars=6, mse = 0.076971\n",
      "selected = view ...\n",
      "totalvars=7, mse = 0.072958\n",
      "selected = bathrooms ...\n",
      "totalvars=8, mse = 0.071181\n",
      "selected = sqft_lot15 ...\n",
      "totalvars=9, mse = 0.069742\n",
      "selected = condition ...\n",
      "totalvars=10, mse = 0.068612\n",
      "selected = waterfront ...\n",
      "totalvars=11, mse = 0.067585\n",
      "selected = floors ...\n",
      "totalvars=12, mse = 0.066764\n",
      "selected = sqft_lot ...\n",
      "totalvars=13, mse = 0.066605\n",
      "selected = sqft_above ...\n",
      "totalvars=14, mse = 0.066443\n",
      "selected = yr_renovated ...\n",
      "totalvars=15, mse = 0.066329\n",
      "selected = bedrooms ...\n",
      "totalvars=16, mse = 0.066268\n",
      "selected = sqft_basement ...\n",
      "totalvars=17, mse = 0.066268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16, 13, 2, 14, 8, 11, 6, 1, 15, 7, 5, 4, 3, 9, 12, 0, 10]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    \n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        \n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "            \n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "        \n",
    "    return selected\n",
    "\n",
    "'''Revise si la cantidad de etiquetas concuerda con la cantidad de variables que esta utilizando,\n",
    "puede que tenga que eliminar un elemento de la lista name_regressors'''\n",
    "\n",
    "names_regressors = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",                     \n",
    "    \"condition\",\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"lat-long\", \n",
    "    \"sqft_living15\",\"sqft_lot15\",\"intercept\"]\n",
    "\n",
    "fss(Xm,ym,names_regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el dataframe de la actividad anterior,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Ajuste un modelo lineal utilizando \"Ridge Regression\", es decir, regularizando con la norma $\\ell_2$. Utilice\n",
    "valores del parámetro de regularización $\\lambda^{‡}$ en el rango $[10^4 , 10^{−1}]$. Construya un gráfico que muestre los\n",
    "coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. (**Hint**:\n",
    "Note que la lı́nea 4 y el primer argumento en la lı́nea 12 son crı́ticos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['intercept'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1cdddd4a7a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intercept'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mistrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mistrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dsanmartin/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dsanmartin/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['intercept'] not contained in axis"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "X_c = X.copy()\n",
    "X_c = X_c.drop('intercept', axis=1)\n",
    "Xtrain = X_c[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\n",
    "\"condition\",\"grade\",\"sqft_above\",\"sqft_basement\",\"yr_built\",\"yr_renovated\",\"lat-long\",\n",
    "\"sqft_living15\",\"sqft_lot15\"]\n",
    "alphas_ = np.logspace(4,-1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "    ax = plt.gca()\n",
    "\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    print alphas_.shape\n",
    "    print y_arr.shape\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "    \n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$^{‡}$ Se asume la siguiente formulación: $\\min_w ||\\textbf{Y} - \\textbf{Xw}||^2 + \\lambda ||\\textbf{w}||^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Ajuste un modelo lineal utilizando el método \"Lasso\", es decir, regularizando con la norma $\\ell_1$. Utilice valores del parámetro de regularización $\\lambda^{§}$ en el rango $[10^1 ,10^{−2}]$. Para obtener el código, modifique las lı́neas 7 y 9 del ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo Lasso para seleccionar atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas_ = np.logspace(0,-3,base=10)\n",
    "clf = Lasso(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$^{§}$ Se asume la siguiente formulación: $\\min_w \\frac12 ||\\textbf{Y} - \\textbf{Xw}||^2 + \\lambda ||\\textbf{w}||_{\\ell_1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Utilizando \"Ridge Regression\", construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del parámetro de regularización. Discuta lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "Xtest = Xtest.drop('intercept', axis=1)\n",
    "alphas_ = np.logspace(4,-2,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True)\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    yhat_train = model.predict(Xtrain)\n",
    "    yhat_test = model.predict(Xtest)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge')\n",
    "plt.legend(loc=2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Utilizando \"Lasso\", construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del parámetro de regularización. Discuta lo que observa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas_ = np.logspace(0.5,-2,base=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Estime el valor del parámetro de regularización en los métodos anteriores usando validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = lambda y,yhat: np.mean(np.power(y-yhat,2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "k_fold = cross_validation.KFold(len(Xm),10)\n",
    "best_cv_mse = float(\"inf\")\n",
    "model = Lasso(fit_intercept=True)\n",
    "\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    mse_list_k10 = [MSE(model.fit(Xm[train], ym[train]).predict(Xm[val]), ym[val]) \\\n",
    "        for train, val in k_fold]\n",
    "    \n",
    "    if np.mean(mse_list_k10) < best_cv_mse:\n",
    "        best_cv_mse = np.mean(mse_list_k10)\n",
    "        best_alpha = a\n",
    "        print \"BEST PARAMETER=%f, MSE(CV)=%f\"%(best_alpha,best_cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Predicción de Utilidades de Películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema a resolver en esta sección consiste en predecir el volumen de utilidades (en dólares) obtenidas por el estreno (al público, en USA) de una pelı́cula. Especı́ficamente consideraremos dos posibles respuestas: el volumen total de utilidades (total revenue) obtenido durante el fin de semana del estreno y el volumen de utilidades por lugar de proyección (per screen revenue). Los datos a utilizar fueron recolectados en un estudio publicado recientemente por M. Joshi y colegas de la universidad de Carnegie Mellon [3], y corresponden a 1718 pelı́culas realizadas entre 2005 y 2009. Cada pelı́cula, se representa utilizando diversos tipos de atributos\n",
    "\n",
    "1. Texto: A partir de las crı́ticas publicadas para cada pelı́cula (en diversos sitios y antes del estreno), se construyen caracterı́sticas que corresponden a la frecuencia de palabras, parejas de palabras y trı́os de palabras obtenidas de un vocabulario.\n",
    "2. Metadata: (1) Variable binaria que indica si el lugar de origen de la pelı́cula es USA, (2) logaritmo del presupuesto, (3) número de puntos de proyección, (4) género (acción, drama, comedia, etc), (5) Calificación de la MPAA (mayores de catorce, todo espectador, etc), (6) Variable binaria que indica si el estreno se produjo durante un feriado/vacaciones y (7) Número de actores con OSCAR.\n",
    "\n",
    "Los datos pueden ser descargados ejecutando los siguientes comandos en un terminal (sistemas UNIX)\n",
    "\n",
    "```\n",
    "wget http://www.inf.utfsm.cl/~cvalle/movies.tar.gz\n",
    "tar -xzvf movies.tar.gz\n",
    "rm movies.tar.gz\n",
    "```\n",
    "\n",
    "Para facilitar el trabajo, los datos han sido ya preparados en formato matricial. Concretamente usted dispondrá de tres parejas de archivos ($\\textbf{X}$ e $y$): un conjunto de datos de entrenamiento (```train.x.nm``` y ```train.y.dat```), un conjunto de datos de validación para evitar tener que hacer validación cruzada (```dev.x.nm``` y ```dev.y.dat```) y un conjunto de datos de pruebas (```test.x.nm``` y ```test.y.dat```) que, naturalmente, no puede utilizar para construir el modelo. Se incluirán además, dos versiones de los datos. Una de ellas consiste en remover la variable que indica la presencia de actores con OSCAR del conjunto de atributos.\n",
    "\n",
    "El archivo de respuestas ($y$) contiene un dato por fila en el orden correspondiente a las $x$. El archivo con\n",
    "los atributos ($x$) está codificado en formato sparse de matrix market [5] como sigue. La cabecera del archivo\n",
    "pueden aparecer 0, 1 o más comentarios (filas que inician con %). La linea siguiente indica el número de filas,\n",
    "columnas y entradas no nulas de la matriz. Las lı́neas que siguen tienen la estructura ($i, j, \\textbf{X}_{ij}$), es decir indican la fila y columna de la matriz que contiene el tercer elemento. Por ejemplo:\n",
    "\n",
    "```\n",
    "%%MatrixMarket matrix coordinate real general\n",
    "317 145256 658516\n",
    "1 9 14.0\n",
    "1 12 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Lea los archivos de datos y cárguelos en dos dataframe o matrices $\\textbf{X}$, $y$. En el caso de $\\textbf{X}$ es extremadamente importante que mantenga el formato disperso (sparse) (¿porqué?). Si trabaja con matrices use matrices dispersas del tipo ```csr matrix``` o ```csc matrix```. Si prefiere operar sobre un dataframe, puede utilizar los (recientemente introducidos) dataframe dispersos de pandas: *SparseDataFrame*, aunque todavı́a no se tiene una operabilidad completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.io import mmread\n",
    "\n",
    "X = csr_matrix(mmread('test.x.nm'))\n",
    "y = np.loadtxt('test.y.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Construya un modelo lineal que obtenga un coeficiente de determinación (sobre el conjunto de pruebas) de al menos 0.75. A partir de un modelo lineal de *sklearn*, el coeficiente de determinación se obtiene fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "model = lm.LinearRegression(fit_intercept = False)\n",
    "\n",
    "print \"R2=%f\"%model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [1] https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "* [2] Hastie, T.; Tibshirani, R., Friedman, J. (2009), The Elements of Statistical Learning, Second Edition. Springer New York Inc.\n",
    "* [3] Joshi, M., Das, D., Gimpel, K., Smith, N. A. (2010). Movie reviews and revenues: An experiment in text regression. In the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (pp. 293-296). Association for Computational Linguistics.\n",
    "* [4] https://www.dropbox.com/sh/8r1wrblyfokwuq0/AABUEvgcuMxyZht2-KYyBptUa?dl=0\n",
    "* [5] http://math.nist.gov/MatrixMarket/formats.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
